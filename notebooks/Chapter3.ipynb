{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f43be4f-c824-46ac-90c6-2352156e3d2a",
   "metadata": {},
   "source": [
    "# Chapter 3\n",
    "\n",
    "Sampling from the posterior - we have computers, why do we need a closed form for the posterior distribution when we can have a massive numpy array instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669bc5de-d281-400b-bb90-7f9729abfef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "\n",
    "import pybayes\n",
    "\n",
    "sns.set_style(\"white\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07703dbc-ed77-4b55-a33b-046db0c9fd3e",
   "metadata": {},
   "source": [
    "## Sampling from the grid-approximate posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1b7a0a-24aa-492b-9751-973b6b332dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the example from chapter 2 of 9 attempts, 6 successes.\n",
    "posterior = pybayes.utils.grid_approximate_binomial(n=9,\n",
    "                                                    k=6,\n",
    "                                                    grid_size=1000,\n",
    "                                                    prior=None,\n",
    "                                                    plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a42e2-899f-4b15-b9e9-d2f1a89367f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pybayes.utils.plot_nicely(x_vals=posterior[:,0], y_vals=posterior[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb3df6-a08f-4d1c-a59b-b4e2521af9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample this distribution.\n",
    "samples = np.random.choice(posterior[:,0],\n",
    "                           size=int(1e4),\n",
    "                           p=posterior[:,1],\n",
    "                           replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8295935-58b9-4267-afdf-9481529fbe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the sampling - plot the sequence, then the density\n",
    "fig, axes = plt.subplots(nrows=2, figsize=(5,10))\n",
    "sns.scatterplot(x=np.arange(len(samples)), y=samples, alpha=0.2, ax=axes[0])\n",
    "axes[0].set_ylim(0,1)\n",
    "axes[0].set_xlabel('Sequence number')\n",
    "axes[0].set_ylabel('Sampled p')\n",
    "\n",
    "sns.histplot(x=samples, ax=axes[1], element='poly', fill=False)\n",
    "axes[1].set_xlim(0,1)\n",
    "axes[1].set_xlabel('Sampled p')\n",
    "axes[1].set_ylabel('Frequency density')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69f7ba1-30b6-4857-8876-f9d331790f75",
   "metadata": {},
   "source": [
    "Once we have samples from the posterior, we can do things we actually care about, such as point estimates, and compatability intervals (McElreath dislikes the phrase 'confidence interval'). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e93174a-e172-4487-ab65-5f8f32f91157",
   "metadata": {},
   "source": [
    "### Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7de0180-1457-4e01-992e-d060c1ae8d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E.g. 1: what  is the probability that p < 0.5 given our data\n",
    "# and binomial model?\n",
    "\n",
    "# from our grid approximation\n",
    "grid_approx_p_of_half = posterior[posterior[:,0] < 0.5, :][:, 1].sum()\n",
    "print(f'grid result: {grid_approx_p_of_half: .3f}')\n",
    "\n",
    "# from the samples (easier in general)\n",
    "sampled_p_of_half = sum(samples < 0.5) / len(samples)\n",
    "print(f'sampled result: {sampled_p_of_half: .3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c5713f-052f-4083-8a2f-e27a705ef311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E.g 2: what is the 10%-90% interval for our posterior p?  We can get\n",
    "# this trivially from quantiles\n",
    "\n",
    "print('10%\\t90%')\n",
    "print(f'{np.quantile(samples, 0.1):.2f}\\t{np.quantile(samples,0.9):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7fe896-fb18-4f58-808d-9d497dc07ad1",
   "metadata": {},
   "source": [
    "NB the percentile intervals are nice summaries of the distribution, unless the distro is highly skewed, but they're not ideal for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1127eb1d-09ee-4bae-a3ca-acd91b329a73",
   "metadata": {},
   "source": [
    "### Point estimates\n",
    "\n",
    "Note - you don't really need one. The Bayesian parameter estimate is the distribution you just computed, anything else is a discarding of useful information. But if you want one, one option is the maximum a posteriori (MAP) estimate, the mode of the distribution.\n",
    "\n",
    "For the case where we have three successes in three trials, the distribution of p looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f6b8b-c984-4fd0-afc8-c9b03bcc3371",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_three_successes = pybayes.utils.grid_approximate_binomial(n=3,\n",
    "                                                    k=3,\n",
    "                                                    grid_size=1000,\n",
    "                                                    prior=None,\n",
    "                                                    plot=True)\n",
    "# sample this distribution.\n",
    "samples_three_successes = np.random.choice(posterior_three_successes[:,0],\n",
    "                           size=int(1e4),\n",
    "                           p=posterior_three_successes[:,1],\n",
    "                           replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42a1110-f083-4026-ae9f-b2bded1aa46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the grid approximation:\n",
    "mode = x_for_max_y = posterior_three_successes[np.argmax(posterior_three_successes[:, 1]), 0]\n",
    "print(f'MAP from grid: {mode:.2f}')\n",
    "# from the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f0372-05cb-4aa6-bd0a-c5c973370e22",
   "metadata": {},
   "source": [
    "### Sampling to simulate prediction\n",
    "\n",
    "We can use our model to generate dummy data, and use that to influence model design, checking, validation, forecasting, etc.\n",
    "\n",
    "\n",
    "For our binominal model before, for every possible p value there is an implied distribution of outcomes. By combining all these distributions together with the posterior probabilities of each p, we can get a ~ ~ posterior predictive distribution ~ ~. This is a more honest way of showing your predicted outcomes, because you include your uncertainty in your parameters (vs e.g picking the most probable value of p in our globe model and showing the implied distribution from that value). The posterior prediction distro is normally, as a result of incorporating this uncertainty, more spread out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83a7f8a-6707-4400-adec-1c3e08b2131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this as follows.\n",
    "# to simulate the predicted observations for a single value of p in our binomial model, we do:\n",
    "w_predictions = np.random.binomial(n=9, p=0.6, size=10_000) # 10,000 samples of the expected successes in 9 trails, when p=0.9\n",
    "\n",
    "_ = pybayes.utils.hist(w_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e80d9-1e6d-4fa4-a08d-fa7a73cab1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to instead propagate the uncertainty in our p values, we can use the samples from the posterior (from the grid approximation before)\n",
    "w_posterior_predictions = np.random.binomial(n=9, p=samples, size=10_000)\n",
    "\n",
    "_ = pybayes.utils.hist(w_posterior_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fbda00-8b4b-44cc-b798-7c1c52e875fa",
   "metadata": {},
   "source": [
    "In the book, he uses these implied predictions to inspect the observed data (which was WLWWWLWLW) more stringently, by looking at the longest run length and the number of switches. You can run the simulation and plot the expected distribution under our model, and then see how our observation squares with this (longest run 3, number of switches 6). We will do that here, just for fun, and because it seems useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791071ea-b424-4cdf-b060-138641c9fc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97666aa8-e969-4b7b-af91-69c0240165b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for prob in samples:\n",
    "    sequences.append(np.random.choice(['W', 'L'], size=9, p=[prob, 1-prob]))\n",
    "sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fd8550-44d2-4671-926e-a5714a610b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_longest_run(sequence):\n",
    "    \"\"\"This could be a oneliner with `max(len(list(g)) for _, g in groupby(seq))`\"\"\"\n",
    "    longest_run = 0\n",
    "    prev_char = sequence[0]\n",
    "    current_run = 1\n",
    "    for char in sequence[1:]:\n",
    "        if char == prev_char:\n",
    "            current_run += 1\n",
    "            if current_run > longest_run:\n",
    "                longest_run = current_run\n",
    "        else:\n",
    "            current_run = 1\n",
    "        prev_char = char\n",
    "    return longest_run\n",
    "\n",
    "def get_num_switches(sequence):\n",
    "    \"\"\"Oneliner is sum(1 for i in range(1, len(seq)) if seq[i] != seq[i-1])\"\"\"\n",
    "    prev_char = sequence[0]\n",
    "    num_switches = 0\n",
    "    for char in sequence[1:]:\n",
    "        if char != prev_char:\n",
    "            num_switches += 1\n",
    "        prev_char = char\n",
    "    return num_switches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423cca3c-0729-4f92-a607-e7a60fce280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [get_longest_run(x) for x in sequences]\n",
    "switches = [get_num_switches(x) for x in sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4157bb0d-a5bc-4240-9a79-970071098466",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pybayes.utils.hist(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf25b098-b9de-4db4-8cb4-e08a547ab46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pybayes.utils.hist(switches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deffdd5-4f46-4710-b62d-a7b162bed629",
   "metadata": {},
   "source": [
    "Note above that of our observed values (3 and 6), the 6 is a bit suspicious, and is associated with negative correlation between one result and the next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eca731-a534-461b-ac70-3114cc6032b5",
   "metadata": {},
   "source": [
    "## Solutions to exercies (spoilers)\n",
    "\n",
    "novice, avert thy gaze\n",
    "\n",
    "We use `samples` from before - likelihood taken from 9 trials, 6 successes, uniform prior, posterior grid-approximated then sampled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fd6067-2ae3-41f0-8a5c-e11c5e2999cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3E1: P(p < 0.2 | D)\n",
    "(samples < 0.2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbad831-15bf-4c72-afcc-7572a222eddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3E2: P(p>0.8 | D)\n",
    "(samples > 0.8).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892807b3-6507-40e1-846e-42e0a176dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3E3: P(0.2 < p < 0.8 | D)\n",
    "((samples < 0.8) & (samples > 0.2)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091adb0e-05a0-46e1-8cde-64d55a1b8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3E4: for what x does P( p < x | D) = 0.2 ?\n",
    "np.quantile(samples, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1a365-7d16-474d-bc74-2ac65c433974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3E5: for what x does P( p > x | D) = 0.2 ?\n",
    "np.quantile(samples, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd8ea5d-b582-4e16-81a1-3b8e18170e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3E6: which values of p have the narrowest interval equal to 66% of the posterior?\n",
    "# really i should implement HPDI myself. But I shan't\n",
    "\n",
    "arviz.hdi(samples, hdi_prob=0.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d5e27-bcd3-46d8-8043-731ac4665263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3E7: what about if we just want the PI, assuming equal posterior prob above and below the interval?\n",
    "\n",
    "np.quantile(samples, [(1-0.66)/2 ,1-(1-0.66)/2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54210c10-6f30-47ee-a75c-1ec72cbf5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3M1: If we have 8 successes in 15 trials, what would the posterior be?\n",
    "new_posterior = pybayes.utils.grid_approximate_binomial(n=15,\n",
    "                                                    k=8,\n",
    "                                                    grid_size=1000,\n",
    "                                                    prior=None,\n",
    "                                                    plot=False)\n",
    "pybayes.utils.plot_nicely(x_vals=new_posterior[:,0], y_vals=new_posterior[:,1])  # compare with prev, peak is shifted left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b723b89-538c-4744-a054-1dcb454af6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3M2: draw 10,000 samples from the above, then get the 90% HPDI for p.\n",
    "new_samples = np.random.choice(new_posterior[:,0],\n",
    "                           size=int(1e4),\n",
    "                           p=new_posterior[:,1],\n",
    "                           replace=True)\n",
    "pybayes.utils.hist(new_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c3655b-3e01-4565-b38b-9b1b72d95f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arviz.hdi(new_samples, hdi_prob=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7f8ee3-0a0f-465b-87ec-8f8a4db147ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3M3: generate samples from the posterior predictive distribution\n",
    "new_posterior_predictive_samples = np.random.binomial(n=15, p=new_samples, size=10_000)\n",
    "sns.histplot(new_posterior_predictive_samples, discrete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc018cd-9973-4cde-980d-e70ace00b499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the probability of exactly 8 successes?\n",
    "(new_posterior_predictive_samples == 8).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135850f-e426-485c-950b-cde7c53e915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb1af9a-e5fc-4253-9a58-4b81bab642eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1956cf8-2a54-4f2a-9a8c-e6ff42fdee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3M4: what is the probability of 6 waters in 9 tosses? \n",
    "ppd_9_tosses = np.random.binomial(n=9, p=new_samples, size=10_000)\n",
    "(ppd_9_tosses == 6).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc380e-3cc1-4aed-b305-8391eb913ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\",\".join(arviz.hdi(new_samples, hdi_prob=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b99b09-04d8-4860-b0e8-840498d7290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3M5 - as in 3M1 onwards, but now with step function prior at 0.5\n",
    "grid_size = 1000\n",
    "p_grid = np.linspace(0,1, grid_size)\n",
    "prior = np.where(p_grid < 0.5, 0, 2)\n",
    "# grid-approximate the posterior\n",
    "step_posterior = pybayes.utils.grid_approximate_binomial(n=15,\n",
    "                                                    k=8,\n",
    "                                                    grid_size=grid_size,\n",
    "                                                    prior=prior,\n",
    "                                                    plot=False)\n",
    "pybayes.utils.plot_nicely(x_vals=step_posterior[:,0], y_vals=step_posterior[:,1])\n",
    "# draw some samples, find the hpdi\n",
    "step_samples = np.random.choice(step_posterior[:,0],\n",
    "                           size=int(1e4),\n",
    "                           p=step_posterior[:,1],\n",
    "                           replace=True)\n",
    "\n",
    "hpdi = arviz.hdi(step_samples, hdi_prob=0.9)\n",
    "\n",
    "print(f'HPDI: {hpdi[0]:.2f} - {hpdi[1]:.2f}')\n",
    "# make the ppd, find p(8 of 15)\n",
    "step_ppd = np.random.binomial(n=15, p=step_samples, size=10_000)\n",
    "sns.histplot(step_ppd, discrete=True)\n",
    "plt.show()\n",
    "print('p(8 of 15 under step prior)', (step_ppd == 8).mean()) \n",
    "\n",
    "# find p(6 of 9) under this 8/15 posterior \n",
    "step_ppd_9_tosses = np.random.binomial(n=9, p=step_samples, size=10_000)\n",
    "print('p(6 of 9 under step prior)', (step_ppd_9_tosses == 6).mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735378ac-801b-4bf9-ad6d-a0e8a736ca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_posterior = pybayes.utils.grid_approximate_binomial(n=15,\n",
    "                                                    k=8,\n",
    "                                                    grid_size=1000,\n",
    "                                                    prior=None,\n",
    "                                                    plot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006d35b-c6ba-4e8e-be50-b0bf44107340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3M6: I want the width of the HPDI for my posterior to be 0.05 wide. How many times do I need to toss the globe for this?\n",
    "# NB - not sure about this one\n",
    "def hdpi_width(num_trials):\n",
    "    # assume k generated from a binomial with p=0.7.\n",
    "    k = np.random.binomial(n=num_trials, p=0.7)\n",
    "    posterior = pybayes.utils.grid_approximate_binomial(n=int(num_trials),\n",
    "                                                    k=k,\n",
    "                                                    grid_size=100,\n",
    "                                                    prior=None,\n",
    "                                                    plot=False)\n",
    "    samples = np.random.choice(posterior[:,0],\n",
    "                               size=int(1e4),\n",
    "                               p=posterior[:,1],\n",
    "                               replace=True)\n",
    "    hpdi = arviz.hdi(samples, hdi_prob=0.99)\n",
    "    return hpdi[1] - hpdi[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c40a503-f5c3-4be1-844b-4e7c5887d2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_width(num_trials, num_repeats=100):\n",
    "    widths = [hdpi_width(num_trials) for i in range(num_repeats)]      \n",
    "    return np.mean(widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a3082-8be7-4105-bbef-c5d09eae44f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = np.linspace(1, 5000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd2a4e0-b927-45c8-b094-9ed5af5b394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "widths = [mean_width(x) for x in trials]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a3e045-760a-4cf6-8b3d-79609b6dfffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pybayes.utils.plot_nicely(x_vals=trials, y_vals=widths, xlabel='num_trials', ylabel='hpdi_width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9864c28f-21f6-4993-ba08-919e13d32d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(trials, widths)\n",
    "ax.axhline(0.05, color='r', linestyle='--')\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51777776-53be-4a9e-a725-20358e1e4d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3H1. Here male=1, female=0, they represent the gender of first and second-born children\n",
    "birth1 = np.asarray((1,0,0,0,1,1,0,1,0,1,0,0,1,1,0,1,1,0,0,0,1,0,0,0,1,0,\n",
    "0,0,0,1,1,1,0,1,0,1,1,1,0,1,0,1,1,0,1,0,0,1,1,0,1,0,0,0,0,0,0,0,\n",
    "1,1,0,1,0,0,1,0,0,0,1,0,0,1,1,1,1,0,1,0,1,1,1,1,1,0,0,1,0,1,1,0,\n",
    "1,0,1,1,1,0,1,1,1,1), dtype=bool)\n",
    "birth2 = np.asarray((0,1,0,1,0,1,1,1,0,0,1,1,1,1,1,0,0,1,1,1,0,0,1,1,1,0,\n",
    "1,1,1,0,1,1,1,0,1,0,0,1,1,1,1,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "1,1,1,0,1,1,0,1,1,0,1,1,1,0,0,0,0,0,0,1,0,0,0,1,1,0,0,1,0,0,1,1,\n",
    "0,0,0,1,1,1,0,0,0,0), dtype=bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bbe7d6-ac25-419d-a8d6-7e58e9980cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [[0,0], [0,0]]\n",
    "\n",
    "for i in (0,1):\n",
    "    for j in (0,1):\n",
    "        counts[i][j] = sum((birth1 ==i) & (birth2 ==j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be029722-b0e2-462a-9d30-deefa0c54f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(counts, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed97a2-54dd-4d29-b997-852ef08c16b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of boys\n",
    "sum(birth1) + sum(birth2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3781ff2c-1804-42d6-b7d0-18c070500bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the grid-approximate posterior for a birth being a boy? Assume uniform prior.\n",
    "\n",
    "# binomial with observed N = 200, k = 111\n",
    "grid_size = 1000\n",
    "p_grid = np.linspace(0,1, grid_size)\n",
    "# prior = np.where(p_grid < 0.5, 0, 2)\n",
    "# grid-approximate the posterior\n",
    "boy_posterior = pybayes.utils.grid_approximate_binomial(n=200,\n",
    "                                                    k=111,\n",
    "                                                    grid_size=grid_size,\n",
    "                                                    prior=None,\n",
    "                                                    plot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7aa4c7-3018-4fd8-ad04-d1112e6a016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modal_p = boy_posterior[np.argmax(boy_posterior[:, 1]), 0]\n",
    "print('modal probability of a boy', round(modal_p,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9929b8d-569d-44fb-9829-bf162c8c7848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3H2: draw some samples, estimate the 50%, 89%, and 97% HPDIs.\n",
    "boy_samples = np.random.choice(boy_posterior[:,0],\n",
    "                           size=int(1e4),\n",
    "                           p=boy_posterior[:,1],\n",
    "                           replace=True)\n",
    "\n",
    "for hpdi_prob in (0.5, 0.89, 0.97):\n",
    "    hpdi = arviz.hdi(boy_samples, hdi_prob=hpdi_prob)\n",
    "    print(f'HPDI for {hpdi_prob}:\\t{hpdi[0]:.2f} - {hpdi[1]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42778d7d-8df6-4934-bf3d-16db92e11f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3H3. Simulate 10,000 replicates of 200 births. Compare the distribution to the actual count. \n",
    "# NB size parameter is actually irrelevant here. It'll be one point for each p.\n",
    "simulated_lads = np.random.binomial(n=200, p=boy_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc8eb1b-2819-47be-92f2-9c5dcccd94f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(simulated_lads, discrete=True)\n",
    "plt.xlabel('Lads')\n",
    "plt.axvline(111, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4973eb58-468d-431d-babe-844e0f17f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3H4 Now compare 10,000 samples from 100 simulated firstborns to the observed data. How's it looking?\n",
    "firstborns = sum(birth1)\n",
    "\n",
    "# use our samples from the big model\n",
    "simulated_firstborns = np.random.binomial(n=100, p=boy_samples)\n",
    "\n",
    "sns.histplot(simulated_firstborns, discrete=True)\n",
    "plt.xlabel('Firstborn lads')\n",
    "plt.axvline(firstborns, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba0b20e-a0d2-462a-a0d3-e277295dca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3H5 - we have assumed independent first and second births. Check this by looking only at second births\n",
    "# following female first births. Count the number of first borns who were girls, simulate that many births.\n",
    "second_births_following_females = [y for (x,y) in zip(birth1, birth2) if x == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6cd96e-284c-42d0-ac5c-6671df846a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_following_females = len(second_births_following_females)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f431ed3d-8924-49a2-872c-7bd460168e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "boys_following_females = sum(second_births_following_females)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de96b13a-6809-47ce-849f-baa48aaaefeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_seconds = np.random.binomial(n=total_following_females, p=boy_samples)\n",
    "\n",
    "sns.histplot(simulated_seconds, discrete=True)\n",
    "plt.xlabel('Secondborns')\n",
    "plt.axvline(boys_following_females, c='red')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3_11] *",
   "language": "python",
   "name": "conda-env-py3_11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
